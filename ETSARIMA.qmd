# ETS and ARIMA

In this section we will be introducing the ETS and ARIMA models. These two models are essential in any forecaster's toolbox. Before learning about the ARIMA model a few concepts have to be introduced such as stationarity, autocorrelation and lags. We wil then study the ARIMA model and learn how to model a time series.

## Preliminaries

### The autocorrelation function {.unnumbered}

Autocorrelations are important in time series analysis since they basically indicate the degree of similarity between a time series and a lagged version of itself (a previous period). This is useful for identifying patterns and trends in the data, but mainly for predicting future values. For example, if a time series exhibits a strong positive autocorrelation at a lag of k time periods, it is likely that the value at time t+k will be similar to the value at time t. Formally we can write the autocorrelation as:

<center>$\rho_{y_t,y_{t-k}}=\frac{cov(y_t,y_{y-k})}{sd(y_t)sd(y_{t-k})}$</center>

We can use this metric to identify which periods are influential for our targeted forecasted periods. As a consequence, we can illustrate a function of a series and it's correlation with its lags to identify/quantify crucial periods. To construct an autocorrelation function start by loading the data and coercing the period variable to a date.

```{r, message=FALSE, warning=FALSE}
library(fpp3)
library(tidyverse)
deliveries<-read_csv("https://jagelves.github.io/Data/tsla_deliveries.csv")

deliveries$period<-yearquarter(deliveries$period)

```

The autocorrelation function can now be constructed by using the `ACF()` function and plotting it with `autoplot()` as shown below.

```{r}
deliveries %>%
  as_tsibble(index=period, regular=T) %>% ACF(lag_max = 12) %>%
  autoplot()+theme_classic()
```

The plot shows that the series is correlated with the first lag the strongest, and that there is a continuous decay as the lags get larger.

### The partial autocorrelation function {.unnumbered}

The **partial autocorrelation function** (PACF) is a summary of the relationships between an observation in a time series with observations at prior time steps, with the relationships of intervening observations removed. The sample partial autocorrelation at lag k is the correlation that results after removing the effect of any correlations due to the terms at shorter lags.

In other words when we calculate the autocorrelation between $y_t$ and $y_{t+k}$, information flows from $t$ to $t+k$, so that indirectly $\rho_k$  accounts for the contribution of the random variables between $t$ and $t+k$. 


## The ar model

## The ma model

## The arima model
