# Model Benchmarks

This module will introduce the modeling procedure by illustrating the process with four different benchmarks (Naive, LS, Mean, and Drift). We will then calculate accuracy measures for each of these benchmarks (e.g., Mean Error, Mean Absolute Error, Root Mean Squared Error, among others). In general, these accuracy measures compare the fitted values with the actual values. As an initial rule, a good model will account for most of the series's variation, leaving a small random error. In the end, we will use the model with the best accuracy to generate a forecast of our series.

## Benchmarks

One of the most intuitive (but naive) predictions we can make about the future is to expect that the value of a variable will behave as it did in the past. A **naive prediction** sets the prediction of a future period to the value of the preceding period. For example, if you consider the task of predicting your weight, a simple heuristic would be to think that your weight tomorrow be the same as the weight observed today. Mathematically we would write:

<center>$\hat y_{T+h}=y_T$

</center>

where $\hat y_{T+h}$ is the predicted value for $h$ periods ahead, and $y_T$ is the value observed at the current time period $T$. We can adjust the Naive prediction by accounting for some natural **drift** (an increase or decrease). Thinking about weight once again, we note that as kids grow, we expect their weight to be close to the previous measurement but slightly higher as we need to account for growth. We would "drift" the naive prediction upward. Mathematically we would write:

<center>$\hat y_{T+h}=y_T+h(\frac{y_t-y_1}{T-1})$

</center>

where $h(\frac{y_t-y_1}{T-1})$ can be thought as the average increase of $y$ from period $1$ to the current period $T$. One could also predict weight by observing your weight during a period and **averaging** the values. Every day the data recorded would be slightly different, but if diets, exercise, sleep, etc., remain relatively constant, the mean could be a good predictor of your future weight. Formally:

<center>$\hat y_{T+h}=\frac{(y_1+y_2+...+y_T)}{T}$

</center>

Lastly, we can use the weight data collected from a period and observe if there is any trend. If we find ourselves motivated to lose weight we can start recording our weight every day. Ideally, we will start seeing the effect of a diet, exercise and healthy sleep in the data. We can predict tomorrows weight by taking into account the downward **trend** of our weight. Formally:

<center>$\hat y_{T+h}=b_0+b_1(T+h)$

</center>

## Modeling the the Average Price of Avocados

Let's apply the forecasting methods to the average prices for avocados in California. Start by loading the `fpp3` package and importing the data.
```{r warning=FALSE, echo=TRUE, message=FALSE}
library(tidyverse)
library(fpp3)
cali<-read_csv("https://jagelves.github.io/Data/CaliforniaAvocado.csv")
```

Recall, that we can create a tsibble from the csv file by using the `as_tsibble()` function. Recall that the index is set to the *date* variable which is recorded weekly.

```{r}
cali %>%
  as_tsibble(key=c(geography),
             index=date, regular=T) -> calits
```

Now we will use the `model()` function to run the benchmarks discussed in section 5.1. We have saved the models to an object called *fit*.

```{r}
fit <- model(calits,mean=MEAN(average_price),
              Naive=NAIVE(average_price),
              Drift=RW(average_price~drift()),
              LS=TSLM(average_price~date))
```

To explore the model coefficients, we use the `coef()` function. To make the output table visually appealing, you can format by using the `gt` package.

```{r ,echo=FALSE}
library(gt)
coef(fit) %>% gt() %>% 
  cols_align("center") %>% 
  tab_header(title = 
               md("**Model Coefficients For The Avocado Data**")) %>% tab_style(locations =                                                    cells_column_labels(columns = everything()),
  style = list(cell_borders(sides = "bottom", weight = px(3)),
    cell_text(weight = "bold"))) %>% 
  fmt_number(columns =c(statistic,estimate,std.error,p.value),
             decimals = 2)
```

The table illustrates the estimates for all the models discussed. Note that the naive method has no estimate, as it is simply the previous period's observed value. Below we illustrate the least squares model by the red line and the Naive model by the orange line.

```{r, warning=FALSE}
calits %>% autoplot(average_price) + theme_classic() + 
  geom_line(aes(y = .fitted), col="red",
            data = augment(fit) %>% filter(`.model`=="LS")) +
geom_line(aes(y = .fitted), col="orange",
            data = augment(fit) %>% filter(`.model`=="Naive"))
```

## Model Fit

The model fit will be assessed by comparing the fitted values against actual values. In general, a good fit is determined by how far the fitted values are from the actual ones. If we square all of the distances (i.e., errors) and then average them, we calculate the Mean Squared Error (MSE).  

<center>$MSE = \frac{ \sum (\hat{y}_t-y_t)^2}{T}$</center>

How we decide to aggregate our errors will determine our measure of accuracy. For example, if we follow the same procedure as the one for MSE's but then find the square root, we have calculated the RMSE. Below you will find a collection of accuracy measures for our benchmarks. You will notice that the Naive method provides the best results since all the accuracy metrics are the smallest. We highlighted these results and made the table more appealing using the `gt` library.

```{r, results=FALSE}
accuracy(fit)
```

```{r, echo=FALSE}
accuracy(fit) %>% gt() %>%
  cols_align("center") %>% 
  tab_header(title = md("**Model Fit**")) %>% 
  tab_style(locations = cells_column_labels(columns = everything()),
  style = list(cell_borders(sides = "bottom", weight = px(3)),
    cell_text(weight = "bold"))) %>% 
  fmt_number(columns =c(ME,RMSE,MAE,MPE,MAPE,MASE,RMSSE,ACF1),
             decimals = 2) %>% 
  tab_style_body(
    style = cell_fill(color="lightgreen"),
    values = "Naive",
    targets ="row")
```

## Forecast

The forecast of the series is obtained by using the `forecast()` function and specifying the number of periods ($h$) needed to be forecasted. We can easily do this in R with the following code:

```{r}
calits_fc<-fit %>% forecast(h=8)
```

```{r, warning=FALSE}
calits_fc %>% autoplot(level=NULL) + theme_classic() + 
  autolayer(calits, average_price)
```

The graph illustrates the forecasts of the four methods. Note how the mean model performs poorly for this series, given that the series exhibit an upward trend. It is also apparent that none of these methods takes into account the seasonal pattern discussed in Section 4. In the next chapter, we will be looking at two models that model both the trends and seasonality of the data.

## Leasons Learned

In this module you have been introduced to the general procedure in forecasting time series.

-   Learning how create forecasts with simple heuristics.

## Readings

@FPP3 chapter 5.
