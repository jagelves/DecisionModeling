# Decisions Under Uncertainty

In this module we will learn how to create decision models. These models rely on probability and expected values. We will map the decision process using a decision tree and value each decision with an expected monetary value. Our objective is to identify the best decision given the possible choices and uncertainty.

## Expected Value

Imagine you are the CEO of a retail company, and you are considering whether to launch a new product line. You have conducted market research and have estimated two possible outcomes based on customer demand and competition:

**Success Scenario:** If the new product line is well-received by customers and captures a significant market share, you anticipate an annual profit of $5 million.
**Failure Scenario:** If the new product line fails to gain traction in the market, you estimate an annual loss of $3 million due to production costs and missed opportunities.

In this decision, you face uncertainty regarding customer preferences, market conditions, and competitive dynamics. The new product line's success or failure will determine your company's financial outcome.

To make an informed decision, you can further assess the probabilities of each outcome based on your market research, historical data, and expert opinions (consultant). For example, you might estimate a 60% chance of success and a 40% chance of failure.

Using this information, you can calculate the expected value of the decision by multiplying the monetary value of each outcome by its respective probability and summing them up:

Expected Value = (Prob. of Success * Value of Success) + (Prob. of Failure * Value of Failure) 

Expected Value = (0.6 * 5 million) + (0.4 * -3 million) 

Expected Value = 3 million + (-1.2 million) 

Expected Value = 1.8 million 


The **expected value** estimates the average monetary outcome you can expect from the decision. In this example, the expected value is positive, suggesting that launching the new product line has a positive profit on average. Mathematically we express the expected value as the sum product of probabilities and monetary values. 

$\sum p_{i}x_{i}$

where $p_{i}$ is the probability of decision $i$ and $x_{i}$ is the monetary values resulting from decision $i$. Notice that if we had other decisions, we could also calculate their expected value. Hence, the expected value allows us to rank and choose decisions that yield the highest monetary value on average.

## Decision Trees

```{mermaid theme=darkly}
%%| fig-width: 5
graph LR
    A[ ] -->|Try| C[ ]
    A[ ] -->|Not Try| B( 0 )
    C -->|Stop| D( 1 )
    C -->|Continue| E( -1 )
```



To solve decision trees we use backward induction:

Start at the end of the tree (right). Choose the branch that leads to the highest payoff for each of the last decision nodes. Repeat procedure while moving backwards to the initial node.

To solve decision trees with uncertainty use the folding-back procedure. Starting from the right of the decision tree and working back to the left at each probability node calculate the EMV. At each decision node, take the maximum of EMV's to identify the optimal decision.

## Bayes' Theorem

How does new information affect our prior expectations?

The Expected Value of Information (EVI): The increase in the expected value that the information generates (i.e. is what we gain by getting the information for free).

The Expected Value of Free and Perfect Information: The increase in the expected value that the perfect information generates (i.e. is what we gain by getting the free and accurate information).

## Readings

## Lessons Learned

-   Learn how to use the Expected Value and Decisions Trees to evaluate different alternatives.

-   Learn how to apply Bayes' Theorem to correctly update the probabilities in your model.

-   Learn how to model different Risk Profiles.
